{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01 Tokenization_Convert to ids.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGmMit2-W7cg"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "import torch"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gRWgumeXNSw"
      },
      "source": [
        "# load the Model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yy0c6jYMXW2w"
      },
      "source": [
        "senetnce = 'I love Mysore'"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3tM5W2tXfIv",
        "outputId": "c630a2b2-e9be-4d94-aabb-ba574de9c33d"
      },
      "source": [
        "tokens = tokenizer.tokenize(senetnce) # Tokenize the sentence\n",
        "tokens"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'love', 'mysore']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pb2i4CWJXjvS",
        "outputId": "709380d8-c62b-4354-f515-5f2819cff5da"
      },
      "source": [
        "# Convert to ids\n",
        "tokenizer.convert_tokens_to_ids(tokens)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1045, 2293, 20761]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    }
  ]
}