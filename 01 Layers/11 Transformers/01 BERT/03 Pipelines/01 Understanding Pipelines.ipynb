{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Pipelines:\n",
    "\n",
    "How can I leverage State-of-the-Art Natural Language Models with only one line of code.\n",
    "\n",
    "The pipelines are a great and easy way to use models for inference.\n",
    "\n",
    "pipelines provides a high-level, easy to use, API for doing inference over a variety of downstream-tasks, \n",
    "\n",
    "Including:\n",
    "\n",
    "    Sentence Classification (Sentiment Analysis): \n",
    "        Indicate if the overall sentence is either positive or negative. \n",
    "        (Binary Classification task or Logitic Regression task)\n",
    "\n",
    "    Token Classification (Named Entity Recognition, Part-of-Speech tagging): \n",
    "        For each sub-entities (tokens) in the input, assign them a label (Classification task).\n",
    "\n",
    "    Question-Answering: \n",
    "        Provided a tuple (question, context) the model should find the span of text in content answering the question.\n",
    "\n",
    "    Mask-Filling: \n",
    "        Suggests possible word(s) to fill the masked input with respect to the provided context.\n",
    "\n",
    "    Feature Extraction: \n",
    "        Maps the input to a higher, multi-dimensional space learned from the data.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Pipelines encapsulate the overall process of every NLP process:\n",
    "\n",
    "        1. Tokenization: Split the initial input into multiple sub-entities with ... properties (i.e. token)\n",
    "        2. Inference: Maps every tokens into a more meaningful representation.\n",
    "        3. Decoding: Use the above representation to generate and/or extract the final output for the underlying task.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "pipeline() method with the following structure:\n",
    "\n",
    "'''\n",
    "from transformers import pipeline\n",
    "\n",
    "# Using default model and tokenizer for the task\n",
    "pipeline(\"<task-name>\")\n",
    "\n",
    "# Using a user-specified model\n",
    "pipeline(\"<task-name>\", model=\"<model_name>\")\n",
    "\n",
    "# Using custom model/tokenizer as str\n",
    "pipeline('<task-name>', model='<model name>', tokenizer='<tokenizer_name>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Sentiment analysis pipeline\n",
    "classifier = pipeline('sentiment-analysis')\n",
    "\n",
    "classifier(\"food was bad\")\n",
    "\n",
    "# output : [{'label': 'NEGATIVE', 'score': 0.9997574090957642}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example for 'sentiment-analysis' pipeline\n",
    "\n",
    "from transformers import pipeline, AutoModelForTokenClassification, AutoTokenizer\n",
    "\n",
    "# Sentiment analysis pipeline\n",
    "pipeline('sentiment-analysis')\n",
    "\n",
    "# Question answering pipeline, specifying the checkpoint identifier\n",
    "pipeline('question-answering', model='distilbert-base-cased-distilled-squad', tokenizer='bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example for NER pipeline\n",
    "\n",
    "# Named entity recognition pipeline, passing in a specific model and tokenizer\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "pipeline('ner', model=model, tokenizer=tokenizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
