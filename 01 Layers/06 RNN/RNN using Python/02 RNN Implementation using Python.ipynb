{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "#sin_wave = np.array([math.sin(x) for x in np.arange(200)])\n",
    "sin_wave = np.arange(0,50)\n",
    "\n",
    "sin_wave\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "seq_len = 4\n",
    "num_records = len(sin_wave) - seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sin_wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(num_records - 2):\n",
    "    X.append(sin_wave[i:i+seq_len])\n",
    "    Y.append(sin_wave[i+seq_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0, 1, 2, 3]),\n",
       " array([1, 2, 3, 4]),\n",
       " array([2, 3, 4, 5]),\n",
       " array([3, 4, 5, 6]),\n",
       " array([4, 5, 6, 7])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "We are considering first 4 records as input and Next immediate record as output \n",
    "You can see the same below\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the input data in teh format of [batchsize,timestep,input feaures]\n",
    "\n",
    "X = np.array(X)\n",
    "X = np.expand_dims(X, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44, 4, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape  # batches = 44; timestep 4; input features = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]   # first sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestep = 4\n",
    "\n",
    "hidden_dim = 8 # hidden unit\n",
    "output_dim = 1\n",
    "\n",
    "learning_rate = 0.0001\n",
    "\n",
    "bptt_truncate = 5\n",
    "min_clip_value = -10\n",
    "max_clip_value = 10\n",
    "\n",
    "\n",
    "U = np.random.uniform(0, 1, (hidden_dim, timestep))  # weights between input and hidden layers\n",
    "V = np.random.uniform(0, 1, (output_dim, hidden_dim)) # weights between hidden and output layers\n",
    "W = np.random.uniform(0, 1, (hidden_dim, hidden_dim)) # shared weights in the RNN layer (hidden layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array(Y).reshape(len(Y),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44, 1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Model\n",
    "loss = []\n",
    "\n",
    "val_loss = 0.0\n",
    "for epoch in range(10):\n",
    "    \n",
    "    for i in range(Y.shape[0]):\n",
    "\n",
    "        x,y = X[i],Y[i]\n",
    "\n",
    "        layers = []\n",
    "\n",
    "        prev_s = np.zeros((hidden_dim,1))\n",
    "\n",
    "        dU = np.zeros(U.shape)\n",
    "        dV = np.zeros(V.shape)\n",
    "        dW = np.zeros(W.shape)\n",
    "\n",
    "        dU_t = np.zeros(U.shape)\n",
    "        dV_t = np.zeros(V.shape)\n",
    "        dW_t = np.zeros(W.shape)\n",
    "\n",
    "\n",
    "        # forward pass\n",
    "        for t in range(timestep):\n",
    "            new_input = np.zeros(x.shape)\n",
    "            new_input[t] = x[t]\n",
    "            mulu = np.dot(U, new_input)\n",
    "            mulw = np.dot(W, prev_s)\n",
    "            add = mulw + mulu\n",
    "            s = sigmoid(add)\n",
    "            mulv = np.dot(V, s)\n",
    "            layers.append({'s':s, 'prev_s':prev_s})\n",
    "            prev_s = s\n",
    "\n",
    "        # derivative of pred\n",
    "        dmulv = (mulv - y)\n",
    "\n",
    "        # backward pass\n",
    "        for t in range(timestep):\n",
    "            dV_t = np.dot(dmulv, np.transpose(layers[t]['s']))\n",
    "            dsv = np.dot(np.transpose(V), dmulv)\n",
    "\n",
    "            ds = dsv\n",
    "            dadd = add * (1 - add) * ds\n",
    "\n",
    "            dmulw = dadd * np.ones_like(mulw)\n",
    "\n",
    "            dprev_s = np.dot(np.transpose(W), dmulw)\n",
    "\n",
    "            for i in range(t-1, max(-1, t-bptt_truncate-1), -1):\n",
    "                ds = dsv + dprev_s\n",
    "                dadd = add * (1 - add) * ds\n",
    "\n",
    "                dmulw = dadd * np.ones_like(mulw)\n",
    "                dmulu = dadd * np.ones_like(mulu)\n",
    "\n",
    "                dW_i = np.dot(W, layers[t]['prev_s'])\n",
    "                dprev_s = np.dot(np.transpose(W), dmulw)\n",
    "\n",
    "                new_input = np.zeros(x.shape)\n",
    "                new_input[t] = x[t]\n",
    "                dU_i = np.dot(U, new_input)\n",
    "                dx = np.dot(np.transpose(U), dmulu)\n",
    "\n",
    "                dU_t += dU_i\n",
    "                dW_t += dW_i\n",
    "\n",
    "            dV += dV_t\n",
    "            dU += dU_t\n",
    "            dW += dW_t\n",
    "\n",
    "            if dU.max() > max_clip_value:\n",
    "                dU[dU > max_clip_value] = max_clip_value\n",
    "            if dV.max() > max_clip_value:\n",
    "                dV[dV > max_clip_value] = max_clip_value\n",
    "            if dW.max() > max_clip_value:\n",
    "                dW[dW > max_clip_value] = max_clip_value\n",
    "\n",
    "\n",
    "            if dU.min() < min_clip_value:\n",
    "                dU[dU < min_clip_value] = min_clip_value\n",
    "            if dV.min() < min_clip_value:\n",
    "                dV[dV < min_clip_value] = min_clip_value\n",
    "            if dW.min() < min_clip_value:\n",
    "                dW[dW < min_clip_value] = min_clip_value\n",
    "\n",
    "        # update\n",
    "        U -= learning_rate * dU\n",
    "        V -= learning_rate * dV\n",
    "        W -= learning_rate * dW\n",
    "\n",
    "        loss_per_record = (y - mulv)**2 / 2\n",
    "        val_loss += loss_per_record\n",
    "\n",
    "    val_loss = val_loss / float(y.shape[0])\n",
    "    loss.append(val_loss[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6743.100886278886,\n",
       " 13432.204639709826,\n",
       " 20068.100203151153,\n",
       " 26651.559546702316,\n",
       " 33183.347167994354,\n",
       " 39664.24067247593,\n",
       " 46095.00677951323,\n",
       " 52476.40069570372,\n",
       " 58809.16633405147,\n",
       " 65094.02744583083]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
