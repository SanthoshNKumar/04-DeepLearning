{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Model API Overview\n",
    "\n",
    "    - The Model Class\n",
    "        - Model Class\n",
    "        - summary\n",
    "        - get_layer\n",
    "    \n",
    "    - Sequential Class\n",
    "        - Sequential\n",
    "        - add\n",
    "        - pop\n",
    "    \n",
    "    - Model training\n",
    "        - compile \n",
    "        - fit\n",
    "        - evaluate\n",
    "        - predict\n",
    "        - train_on_batch\n",
    "        - test_on_batch\n",
    "        - predict_on_batch\n",
    "        - run_eagrely\n",
    "        \n",
    "    - Model saving & serialization\n",
    "        - save model\n",
    "        - load model\n",
    "        - get_weights\n",
    "        - set_weights\n",
    "        - save_weights\n",
    "        - load_weights\n",
    "        - get_config\n",
    "        - from_config\n",
    "        - model_from_config\n",
    "        - to_json\n",
    "        - model_from_json\n",
    "        - clone_model\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Model : Model groups layers into an object with training and inference features.\n",
    "   \n",
    "tf.keras.Model()\n",
    "\n",
    "    Arguments \n",
    "        - inputs\n",
    "        - outputs\n",
    "        - name\n",
    "        \n",
    "Ways of  Models can be instantiated:\n",
    "    - Functional API\n",
    "    - subclassing \n",
    "'''\n",
    "\n",
    "# Example using Functional API\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "inputs = tf.keras.Input(shape=(3,))\n",
    "\n",
    "x = tf.keras.layers.Dense(4, activation=tf.nn.relu,name=\"l1\")(inputs)\n",
    "outputs = tf.keras.layers.Dense(5, activation=tf.nn.softmax)(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "l1 (Dense)                   (None, 4)                 16        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 25        \n",
      "=================================================================\n",
      "Total params: 41\n",
      "Trainable params: 41\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Print Model Summary\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-5.4009080e-02,  5.7458210e-01, -2.7516484e-03,  9.0599191e-01],\n",
       "        [ 1.6134977e-04, -1.2369752e-03,  9.7188592e-02, -1.8547463e-01],\n",
       "        [ 5.4360723e-01, -4.7398642e-01,  8.3838809e-01,  1.9523871e-01]],\n",
       "       dtype=float32), array([0., 0., 0., 0.], dtype=float32)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get_layer and get weights\n",
    "\n",
    "model.get_layer('l1').get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "  Types of Keras Models Creation\n",
    "    -  Sequential Model\n",
    "            - The Sequential model is a linear stack of layers.\n",
    "            - Passing a list of layers to the constructor\n",
    "            - Simply add layers via the .add() method:\n",
    "    -  Functional API\n",
    "            - It allows us to define multiple input or output models as well as models that share layers.\n",
    "            - Input() is used to define the input layer with input shape as an argumentshape=(4,)\n",
    "            - Only things we need to reference in Model() are the inputs and outputs tensors\n",
    "    -  Sub Classing\n",
    "            - Implement everything from scratch on your own\n",
    "            - Use this if you have complex, out-of-the-box research use cases.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "When to use Sequential Model\n",
    "\n",
    "A Sequential model is appropriate for a plain stack of layers where each layer has exactly one input and one output\n",
    "\n",
    "A Sequential model is not appropriate \n",
    "    - Your model has multiple inputs or multiple outputs\n",
    "    - Any of your layers have multiple inputs or multiple outputs\n",
    "    - You need to do layer sharing\n",
    "    - You want non-linear topology (e.g. a residual connection, a multi-branch model)\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential Model  : Linear Stack of layer\n",
    "\n",
    "model = Sequential([Dense(32,input_shape=(784,)),Activation('relu'), Dense(10),Activation('softmax')])\n",
    "\n",
    "#or\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(32,input_shape=(784,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get unmber of layers in in the model\n",
    "\n",
    "len(model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add method : Adds a layer instance on top of the layer stack.\n",
    "\n",
    "model.add(Dense(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pop method : Removes the last layer in the model\n",
    "\n",
    "model.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get unmber of layers in in the model\n",
    "\n",
    "len(model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\insakum46\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 1000 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 337us/sample - loss: 5.5926 - acc: 0.0970\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 77us/sample - loss: 3.7449 - acc: 0.1000\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 74us/sample - loss: 3.6562 - acc: 0.1010\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 70us/sample - loss: 3.6326 - acc: 0.1110\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 70us/sample - loss: 3.6255 - acc: 0.1150\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 73us/sample - loss: 3.6202 - acc: 0.1260\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 73us/sample - loss: 3.6139 - acc: 0.1260\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 81us/sample - loss: 3.6045 - acc: 0.1190\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 79us/sample - loss: 3.6001 - acc: 0.1210\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 75us/sample - loss: 3.5940 - acc: 0.1450\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19d0c6758c8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Functional API : Exmaple\n",
    "\n",
    "data = np.random.random((1000, 100))\n",
    "labels = np.random.randint(10, size=(1000, 1))\n",
    "\n",
    "# Convert labels to categorical one-hot encoding\n",
    "one_hot_labels = to_categorical(labels, num_classes=10)\n",
    "\n",
    "inputs = Input(shape=(100,))\n",
    "output_1 = Dense(32, activation='relu')(inputs)\n",
    "predictions = Dense(10, activation='relu')(output_1)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predictions) # Model API Used when Function al API are Used\n",
    "\n",
    "# Compile\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "# Train the model, iterating on the data in batches of 32 samples\n",
    "model.fit(data, one_hot_labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Life Cycle of Model Creation in Keras\n",
    "\n",
    "Model Creation --> Model Compilation ---> Model Fit--> Evaluate Network --> Model Predict\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Interpretign the Model\n",
    "\n",
    "model = Sequential() \n",
    "model.add(Dense(512, activation = 'relu', input_shape = (784,))) \n",
    "model.add(Dropout(0.2)) \n",
    "model.add(Dense(512, activation = 'relu'))\n",
    "model.add(Dropout(0.2)) \n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "# Compile Model\n",
    "model.compile(loss = 'categorical_crossentropy',optimizer = RMSprop(), metrics = ['accuracy'])\n",
    "\n",
    "# Training Model\n",
    "history = model.fit(x_train, y_train, batch_size = 128, epochs = 20, verbose = 1, validation_data = (x_test, y_test))\n",
    "\n",
    "1. Input layer consists of 784 values (28 x 28 = 784).\n",
    "2. First hidden layer, Dense consists of 512 neurons and ‘relu’ activation function.\n",
    "3. Second hidden layer, Dropout has 0.2 as its value.\n",
    "4. Third hidden layer, again Dense consists of 512 neurons and ‘relu’ activation function.\n",
    "5. Fourth hidden layer, Dropout has 0.2 as its value.\n",
    "6. Fifth and final layer consists of 10 neurons and ‘softmax’ activation function.\n",
    "7. Use categorical_crossentropy as loss function.\n",
    "8. Use RMSprop() as Optimizer.\n",
    "9. Use accuracy as metrics.\n",
    "10. Use 128 as batch size.\n",
    "11. Use 20 as epochs.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Layer\n",
    "\n",
    "# You can also simply add layers via the .add() method\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32,input_dim=784))\n",
    "model.add(Activation('relu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilation : Before training a model, you need to configure the learning process, which is done via the compile method. \n",
    "# It receives three arguments:\n",
    "\n",
    "# For a multi-class classification problem\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].get_weights()[0].shape  # weight siz of (784,32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 8)                 88        \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 129\n",
      "Trainable params: 129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get Model Summary\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(8,input_shape=(10,),activation='relu'))\n",
    "model.add(Dense(4,activation='relu'))\n",
    "model.add(Dense(1,activation='linear'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the shape of Layer 0\n",
    "\n",
    "model.layers[0].get_weights()[0].shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the share of output layer\n",
    "\n",
    "model.layers[2].get_weights()[0].shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.84960663],\n",
       "        [-0.20277429],\n",
       "        [-0.86632174],\n",
       "        [ 0.5413501 ]], dtype=float32), array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[2].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Specifying the Input Shape\n",
    "\n",
    "01 using input_shape\n",
    "\n",
    "Example\n",
    "\n",
    "''''\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_shape=(784,)))\n",
    "\n",
    "\n",
    "'''\n",
    "02 using input_dim\n",
    "\n",
    "Example\n",
    "\n",
    "'''\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=784))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Model creation with Weight Initializer (Kernel Initilizer)\n",
    "\n",
    "'''\n",
    "\n",
    "#Initialize\n",
    "model = Sequential()\n",
    "\n",
    "my_init = initializers.Zeros() \n",
    "model.add(layers.Dense(512, activation = 'relu', input_shape = (784,), kernel_initializer = my_init))\n",
    "\n",
    "\n",
    "# Other types of Initilzers\n",
    "\n",
    "initializers.Ones() \n",
    "initializers.Constant(value = 5)\n",
    "initializers.RandomNormal(mean=0.0, stddev = 0.05, seed = None) \n",
    "initializers.RandomUniform(minval = -0.05, maxval = 0.05, seed = None)\n",
    "initializers.TruncatedNormal(mean = 0.0, stddev = 0.05, seed = None)\n",
    "initializers.VarianceScaling(scale = 1.0, mode = 'fan_in', distribution = 'normal', seed = None) \n",
    "\n",
    "#...etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Model Creation with Regularization\n",
    "\n",
    "Different Types of Regularization\n",
    "    1. L2 and L1 regularization\n",
    "    2. Dropout\n",
    "    3. Data augmentation\n",
    "    4. Early stopping\n",
    "'''\n",
    "\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# Define l1 Regularizer\n",
    "my_regularizer = regularizers.l1(0.)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(512,activation='relu',input_shape=(784,),kernel_regularizer=my_regularizer))\n",
    "\n",
    "# Other Regularizers\n",
    "\n",
    "my_regularizer = regularizers.l2(0.)\n",
    "my_regularizer = regularizers.L1L2(0.0,0.0)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Model Creation with Activation Function\n",
    "\n",
    "'''\n",
    "\n",
    "# Initialize Model\n",
    "model = Sequential() \n",
    "\n",
    "# 01 Linear\n",
    "model.add(layers.Dense(512,activation='linear',input_shape=(784,)))\n",
    "\n",
    "# 02 elu (Exponential linear unit.)\n",
    "model.add(layers.Dense(512,activation='elu',input_shape=(784,)))\n",
    "\n",
    "# 04 relu(Rectified Linear Unit.)\n",
    "model.add(layers.Dense(512,activation='relu',input_shape=(784,)))\n",
    "\n",
    "# 05 Softmax\n",
    "model.add(layers.Dense(512,activation='softmax',input_shape=(784,)))\n",
    "\n",
    "#...etc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Model Creation Last Layer Activation and Loss Function bases on the use case\n",
    "\n",
    "'''\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#01 Binary classification - Dog VS Cat\n",
    "\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    model.compile(optimizer = optimizers.RMSprop(lr=1e-4), loss='binary_crossentropy',metrics=['acc'])\n",
    "\n",
    "#02 Multi-class single-label classification - MNIST\n",
    "\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "#03 Regression to arbitrary values - Bosten Housing price prediction\n",
    "\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "\n",
    "#04 Regression to values between 0 and 1\n",
    "\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Model with 2 inputs and 1 output\n",
    "\n",
    "'''\n",
    "\n",
    "from tensorflow.keras.layers import concatenate\n",
    "\n",
    "input_structure = Input(shape=(4,), name='input_structure')\n",
    "input_image = Input(shape=(256,), name='input_image')\n",
    "\n",
    "# middle layers\n",
    "x_1 = Dense(10, activation='relu')(input_structure)\n",
    "x_2 = Dense(100, activation='relu')(input_image)\n",
    "\n",
    "c = concatenate([x_1, x_2])\n",
    "\n",
    "outputs = Dense(3, activation='sigmoid', name='outputs')(c)\n",
    "\n",
    "model = Model(inputs=[input_structure, input_image], outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Model with 1 input and 2 outputs\n",
    "\n",
    "'''\n",
    "\n",
    "from tensorflow.keras.layers import concatenate\n",
    "\n",
    "# only one input\n",
    "input_image = Input(shape=(256,), name='input_image')\n",
    "\n",
    "# middle layer\n",
    "x = Dense(300, activation='relu')(input_image)\n",
    "\n",
    "# output layser\n",
    "output_1 = Dense(1, activation='sigmoid', name='output_1')(x)\n",
    "output_2 = Dense(3, activation='softmax', name='output_2')(x)\n",
    "\n",
    "model = Model(inputs=input_image, outputs=[output_1, output_2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Model with 2 inputs and 2 outputs.\n",
    "\n",
    "'''\n",
    "\n",
    "from tensorflow.keras.layers import concatenate\n",
    "\n",
    "# 2 inputs, one structured data, the other image data\n",
    "input_structured = Input(shape=(4,), name='input_structured')\n",
    "input_image = Input(shape=(256,), name='input_image')\n",
    "\n",
    "# middle layers\n",
    "x_1 = Dense(10, activation='relu')(input_structure)\n",
    "x_2 = Dense(300, activation='relu')(input_image)\n",
    "\n",
    "c = concatenate([x_1, x_2])\n",
    "\n",
    "# output layser\n",
    "output_1 = Dense(1, activation='sigmoid', name='output_1')(c)\n",
    "output_2 = Dense(3, activation='softmax', name='output_2')(c)\n",
    "\n",
    "model = Model(inputs=[input_structured, input_image], outputs=[output_1, output_2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Model with Cross Validation using 'KerasClassifier'\n",
    "'''\n",
    "\n",
    "# Create Function that constructs a neural network\n",
    "def create_network():\n",
    "    \n",
    "    network = Sequential()\n",
    "    network.add(Dense(units =16,activation='relu',input_shape = (100,)))\n",
    "    network.add(Dense(units=16,activation='relu'))\n",
    "    network.add(Dense(units=1,activation = 'sigmoid'))\n",
    "    network.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
    "    \n",
    "    return network\n",
    "    \n",
    "# Wrap Function In KerasClassifier\n",
    "neural_network = KerasClassifier(build_fn=create_network,epochs = 10,batch_size=100,verbose=0)\n",
    "\n",
    "# Conduct k-Fold Cross-Validation Using scikit-learn\n",
    "# Evaluate neural network using three-fold cross-validation\n",
    "cross_val_score(neural_network, features, target, cv=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Model with 'Grid Search CV' for hyperparamter Tuning\n",
    "'''\n",
    "\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create Function that constructs a neural network and takes optimiser as parameter\n",
    "def build_classifers(optimizer):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units =6, kernel_initializer = 'uniform',activation='relu',input_dim=12))\n",
    "    model.add(Dense(units =6,kernel_initializer = 'uniform',activation='relu'))\n",
    "    model.add(Dense(units=1,kernel_initializer='uniform',activation='sigmoid'))\n",
    "    model.compile(optimizer=optimizer,loss = 'binary_crossentropy',metrics = ['accuracy'])\n",
    "    return model\n",
    "    \n",
    "# Wrap Function In KerasClassifier\n",
    "classier =KerasClassifier(build_fn=build_classifers)\n",
    "\n",
    "# Hyper parameters \n",
    "parameters = {'batch_size': [25,32],'epochs':[1,2],'optimizer':['adam','rmsprop']}\n",
    "\n",
    "# Define Grid Seach CV\n",
    "grid_search = GridSearchCV(estimator=classier,param_grid=parameters,scoring='accuracy',cv=10)\n",
    "\n",
    "# Fit the Data\n",
    "grid_search = grid_search.fit(X_train,y_train)\n",
    "\n",
    "# Get the Best Parameters\n",
    "best_parameters = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Model with 'Grid Search CV' for hyperparamter Tuning for finding Activation function\n",
    "\n",
    "'''\n",
    "\n",
    "# Create Function that constructs a neural network and takes optimiser as parameter\n",
    "def create_model(activation='relu'):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=8, kernel_initializer='uniform', activation=activation))\n",
    "    model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "    \n",
    "# Wrap Function In KerasClassifier\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "\n",
    "# define the grid search parameters\n",
    "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "param_grid = dict(activation=activation)\n",
    "\n",
    "# Define Grid Seach CV\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
    "\n",
    "# Fit the Data\n",
    "grid_result = grid.fit(X, Y)   \n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Model Subclassing\n",
    "'''\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "class CustomModel(Model):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super(CustomModel, self).__init__(**kwargs)\n",
    "        self.dense1 = Dense(5, activation='relu', )\n",
    "        self.dense2 = Dense(10, activation='relu')\n",
    "        self.dense3 = Dense(3, activation='softmax')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dense2(x)\n",
    "        return self.dense3(x)\n",
    "    \n",
    "my_custom_model = CustomModel(name='my_custom_model')\n",
    "\n",
    "# Training a Model Subclassing model\n",
    "my_custom_model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "history = my_custom_model.fit(X_train, y_train,batch_size= 64,epochs= 30,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Drop outs:\n",
    "\n",
    "Dropout is a regularization technique to prevent overfitting in a neural network model training\n",
    "\n",
    "The method randomly drops out or ignores a certain number of neurons in the network.\n",
    "\n",
    "How to use Dropout layer in Keras model\n",
    "    1. After the input layer\n",
    "    2. Between the hidden layers\n",
    "    3. Before the output layer\n",
    "    \n",
    "    \n",
    "# 1. After the input layer\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=4, activation=\"relu\")) \n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "# 2. Between the hidden layers\n",
    "\n",
    "model.add(Conv2D())\n",
    "model.add(MaxPooling())\n",
    "model.add(Dropout(0.2)\n",
    "\n",
    "# 3. Before the output layer\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(3, activation=\"softmax\"))\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       x       y\n",
      "0      0  -17.78\n",
      "1      1  -17.22\n",
      "2      2  -16.67\n",
      "3      3  -16.11\n",
      "4      4  -15.56\n",
      "..   ...     ...\n",
      "995  995  535.00\n",
      "996  996  535.56\n",
      "997  997  536.11\n",
      "998  998  536.67\n",
      "999  999  537.22\n",
      "\n",
      "[1000 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[93.64606]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Simple Linear Regression\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "df = pd.read_csv(\"C:\\MyWork\\MyLearning\\Career Growth\\ML\\Files\\DataSet\\Linear-Regression-Data.csv\")\n",
    "\n",
    "x = df.x\n",
    "y = df.y\n",
    "\n",
    "print(df)\n",
    "\n",
    "# Define Model\n",
    "model = Sequential()\n",
    "\n",
    "# Add Model Layer\n",
    "model.add(Dense(32,activation='relu',input_dim=1))\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(1,))\n",
    "\n",
    "# Compile Model\n",
    "optimizer = RMSprop(0.0099)\n",
    "\n",
    "model.compile(optimizer=optimizer,loss='mean_squared_error')\n",
    "model.fit(x,y,epochs=500,verbose=0)\n",
    "\n",
    "# Predict\n",
    "model.predict([200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Save and Load the Keras Model\n",
    "\n",
    "'''\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")    # Save weights\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json and create model\n",
    "\n",
    "json_file = open('model.json', 'r')\n",
    "\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")  # load_weights\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(X, Y, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to YAML\n",
    "\n",
    "model_yaml = model.to_yaml()\n",
    "with open(\"model.yaml\", \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "    \n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")  # Save weights\n",
    "print(\"Saved model to disk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_yaml\n",
    "\n",
    "# load YAML and create model\n",
    "yaml_file = open('model.yaml', 'r')\n",
    "loaded_model_yaml = yaml_file.read()\n",
    "\n",
    "yaml_file.close()\n",
    "\n",
    "loaded_model = model_from_yaml(loaded_model_yaml)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")  # load_weights\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "# evaluate loaded model on test data\n",
    "\n",
    "loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(X, Y, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Save Model Weights and Architecture Together\n",
    "  - Saving the model in this way includes everything we need to know about the model, including\n",
    "    - Model weights.\n",
    "    - Model architecture.\n",
    "    - Model compilation details (loss and metrics).\n",
    "    - Model optimizer state.\n",
    "\n",
    "'''\n",
    "\n",
    "# save model and architecture to single file\n",
    "\n",
    "model.save(\"model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "# Load the Keras model : The function returns the model with the same architecture and weights\n",
    "from keras.models import load_model\n",
    " \n",
    "# load model\n",
    "model = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Note : Difference betweeen 'model.save_weights()' and 'mode.save()'\n",
    "\n",
    "model.save_weights() :will only save the weights so if you need, you are able to apply them on a different architecture\n",
    "\n",
    "mode.save() will save the architecture of the model + the the weights + the training configuration + the state of the optimizer\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get Weight\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.random.randn(100)\n",
    "y = x*3 + np.random.randn(100)*0.8\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(4, input_dim = 1, activation = 'linear', name = 'layer_1'))\n",
    "model.add(Dense(1, activation = 'linear', name = 'layer_2'))\n",
    "model.compile(optimizer = 'sgd', loss = 'mse', metrics = ['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_1\n",
      "Weights\n",
      "Shape:  (1, 4) \n",
      " [[-0.4659645   1.0331597   0.545838   -0.58148044]]\n",
      "Bias\n",
      "Shape:  (4,) \n",
      " [0. 0. 0. 0.] \n",
      "\n",
      "layer_2\n",
      "Weights\n",
      "Shape:  (4, 1) \n",
      " [[0.13917828]\n",
      " [0.28758729]\n",
      " [0.6175275 ]\n",
      " [0.25251186]]\n",
      "Bias\n",
      "Shape:  (1,) \n",
      " [0.] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "get_weight : get the weights and biases of the layers before training the model.\n",
    "\n",
    "'''\n",
    "\n",
    "for layer in model.layers:\n",
    "  print(layer.name)\n",
    "  print(\"Weights\")\n",
    "  print(\"Shape: \",layer.get_weights()[0].shape,'\\n',layer.get_weights()[0])\n",
    "  print(\"Bias\")\n",
    "  print(\"Shape: \",layer.get_weights()[1].shape,'\\n',layer.get_weights()[1],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights and biases of the layers after setting the new weights and biases: \n",
      "\n",
      "layer_1\n",
      "Weights\n",
      "Shape:  (1, 4) \n",
      " [[ 0.5767459   0.01784462  0.35760444 -0.9040189 ]]\n",
      "Bias\n",
      "Shape:  (4,) \n",
      " [1. 1. 1. 1.] \n",
      "\n",
      "layer_2\n",
      "Weights\n",
      "Shape:  (4, 1) \n",
      " [[-0.2023459 ]\n",
      " [ 0.46942163]\n",
      " [-1.0108349 ]\n",
      " [ 1.7490941 ]]\n",
      "Bias\n",
      "Shape:  (1,) \n",
      " [1.] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "set_weights() : setting custtom weights for the layers in the Models\n",
    "\n",
    "'''\n",
    "\n",
    "# Setting new weights and biases\n",
    "for layer in model.layers:\n",
    "  a,b = layer.get_weights()[0].shape\n",
    "  layer.set_weights([np.random.randn(a,b), np.ones(layer.get_weights()[1].shape)])\n",
    "    \n",
    "    \n",
    "print(\"Weights and biases of the layers after setting the new weights and biases: \\n\")\n",
    "for layer in model.layers:\n",
    "  print(layer.name)\n",
    "  print(\"Weights\")\n",
    "  print(\"Shape: \",layer.get_weights()[0].shape,'\\n',layer.get_weights()[0])\n",
    "  print(\"Bias\")\n",
    "  print(\"Shape: \",layer.get_weights()[1].shape,'\\n',layer.get_weights()[1],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "get_config\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from_config\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "model_from_config\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "clone_model\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
