{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Model Compilation :\n",
    "    \n",
    "    Compilation is an efficiency step. \n",
    "    It transforms the simple sequence of layers that we defined into a highly efficient series of \n",
    "    matrix transforms in a format intended to be executed on your GPU or CPU.\n",
    "    \n",
    "    - Before training a model, you need to configure the learning process, which is done via the compile method. \n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Parameters :\n",
    "    - optimiers\n",
    "    - loss\n",
    "    - metrics\n",
    "    - loss_weight\n",
    "    - sample weight\n",
    "    - weighted_metrics\n",
    "    - target_tensors\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define compile  for the model\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Create Model\n",
    "model = Sequential()\n",
    "model.add(Dense(250,activation='relu',input_shape=(20,)))\n",
    "model.add(Dense(250,activation='relu'))\n",
    "model.add(Dense(250,activation='relu'))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "\n",
    "# Compile Model\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Model  with multiple metrics\n",
    "\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy','binary Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Model Training along with SGD\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "sgd = SGD(lr =0.01,decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "# Compile Model\n",
    "model.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Creating and using custom loss function in compile section\n",
    "\n",
    "# Define custom loss\n",
    "def custom_loss(layer):\n",
    "\n",
    "    # Create a loss function that adds the MSE loss to the mean of all squared activations of a specific layer\n",
    "    def loss(y_true,y_pred):\n",
    "        return K.mean(K.square(y_pred - y_true) + K.square(layer), axis=-1)\n",
    "   \n",
    "    # Return a function\n",
    "    return loss\n",
    "    \n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss=custom_loss(layer), # Call the loss function with the selected layer\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Creating and using custom metrics  function in compile Section\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "def mean_pred(y_true, y_pred):\n",
    "    return K.mean(y_pred)\n",
    "\n",
    "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy', mean_pred])\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Loss weight :\n",
    "\n",
    "Optional list or dictionary specifying scalar coefficients (Python floats) to weight the loss contributions of \n",
    "different model outputs.\n",
    "\n",
    "The loss value that will be minimized by the model will then be the weighted sum of all individual losses, \n",
    "weighted by the loss_weights coefficients\n",
    "\n",
    "\n",
    "Ex:\n",
    "loss_weights parameter on compile is used to define how much each of your model output loss contributes \n",
    "to the final loss value ie. it weighs the model output losses. \n",
    "You could have a model with 2 outputs where one is the primary output and the other auxiliary. \n",
    "eg. 1. * primary + 0.3 * auxiliary. \n",
    "The default values for loss weights is 1.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Sample Weight :\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "weighted_metrics: List of metrics to be evaluated and weighted by sample_weight or class_weight during training and testing.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Optimizers \n",
    "    1. Adadelta : Extension of Adagrad : Adadelta(adaptive delta)\n",
    "    2. Adagrad  : Adaptive Gradient Algorithm\n",
    "    3. Adam     : Adaptive Moment Estimation\n",
    "    4. Adamax   :\n",
    "    5. Ftrl     : Follow The Regularized Leader\n",
    "    6. Nadam    : Nesterov-accelerated Adaptive Moment Estimation\n",
    "    7. RMSprop  : Root Mean Square Propagation \n",
    "    8. SGD      : Stochastic Gradient Descent\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Loss Functions\n",
    "    1. mean_squared_error\n",
    "    2. mean_absolute_error\n",
    "    3. mean_absolute_percentage_error\n",
    "    4. mean_squared_logarithmic_error\n",
    "    5. squared_hinge\n",
    "    6. hinge\n",
    "    7. categorical_hinge\n",
    "    8. logcosh\n",
    "    9. huber_loss\n",
    "    10. categorical_crossentropy\n",
    "    11. sparse_categorical_crossentropy\n",
    "    12. binary_crossentropy\n",
    "    13. kullback_leibler_divergence\n",
    "    14. poisson\n",
    "    15. cosine_proximity\n",
    "    16. is_categorical_crossentropy\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Loss function based on the type of usecase\n",
    "\n",
    "For a multi-class classification problem\n",
    "    model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "For a binary classification problem\n",
    "    model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "For a mean squared error regression problem\n",
    "    model.compile(optimizer='rmsprop',loss='mse')\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Metrics\n",
    "    1. AUC : Area Under Curve\n",
    "    2. Accuracy\n",
    "    3. Binary Accuracy\n",
    "    4. BinaryCrossEntropy\n",
    "    5. CategoricalAccuracy\n",
    "    6. CategoricalCrossEntropy\n",
    "    7. CategoricalHinge\n",
    "    8. CosineSimilarity\n",
    "    9. FalseNegative\n",
    "    10. FalsePositive\n",
    "    11. Hinge\n",
    "    12. KLDivergence\n",
    "    13. LogCoshError\n",
    "    14. Mean\n",
    "    15. MeanAbolsuteError\n",
    "    16. MeanAbsolutePercentageError\n",
    "    17. MeanIou\n",
    "    18. MeanRelatievError\n",
    "    19. MeanSqaredError\n",
    "    20. MeanSquaredLogarithmicError\n",
    "    21. MeanTensor\n",
    "    22. Poission\n",
    "    23. PrecisionAtRecall\n",
    "    24. Recall\n",
    "    25. RecallAtPrecision\n",
    "    26. RootMeanSquaredError\n",
    "    27. SensitivityAtSpecificity\n",
    "    28. SparseCatgoricalAccuracy\n",
    "    29. SparseTopKCategoricalAccuracy\n",
    "    30. SpecificityAtSensivity\n",
    "    31. SquardHinge\n",
    "    32. Sum\n",
    "    33. TopKCategoricalAccuracy\n",
    "    34. TrueNegative\n",
    "    35  TruePositives\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
