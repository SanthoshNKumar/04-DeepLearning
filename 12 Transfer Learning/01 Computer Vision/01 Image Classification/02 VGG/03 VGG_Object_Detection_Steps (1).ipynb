{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0qnvseOTLM-z"
   },
   "outputs": [],
   "source": [
    "# steps :\n",
    "\n",
    "1. Load the VGG Module from Keras\n",
    "2. Load the target image of size (224,224)\n",
    "3. Convert img to Array using Keras 'img_to_array'\n",
    "    ex: (224, 224, 3)\n",
    "4. Reshape the image to size of below (1, image.shape[0], image.shape[1], image.shape[2])\n",
    "    ex: (1, 224, 224, 3)\n",
    "5. Process the image converted array using Keras 'preprocess_input'\n",
    "6. Predict the output using module.predict()\n",
    "7. Decode the output using VGG 'decode_predictions'\n",
    "8. Inteprest and get the first forst array value from decoded output \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "140hS-S-nWeD",
    "outputId": "a78be780-d2ae-4454-a6d8-aed970a81757"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "553467904/553467096 [==============================] - 4s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "model = VGG16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "yXZ4YBSlJvHf"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "image = load_img('/content/sample_data/Mug.jpg', target_size=(224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S-j9hnXAKW6Y",
    "outputId": "4f1d1631-de2d-4e1d-d62f-4f5901448997"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "image = img_to_array(image)\n",
    "\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5NfGt7YHKJK_",
    "outputId": "b6b7fbbe-dcb2-4e18-c042-d5ae3ff89d2c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 224, 224, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape data for the model\n",
    "image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "\n",
    "image.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PgAKdxigKDmQ",
    "outputId": "10be265a-d5d9-4db3-9c86-79089c972e9d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 224, 224, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "# prepare the image for the VGG model\n",
    "image = preprocess_input(image)\n",
    "\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PgQAIl7yJjTK",
    "outputId": "3e116de9-a0c6-4d55-9eb5-7f6cf37c87c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('n03063599', 'coffee_mug', 0.738267)"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the prediction\n",
    "yhat = model.predict(image)\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import decode_predictions\n",
    "\n",
    "# convert the probabilities to class labels :Decode the prediction\n",
    "label = decode_predictions(yhat)\n",
    "\n",
    "label[0][0]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "VGG _Object Detection Steps.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
